{
  "cells": [
    {
      "cell_type": "code",
      "id": "Xf5mb6SQU9IqKNLN5PEoALCE",
      "metadata": {
        "tags": [],
        "id": "Xf5mb6SQU9IqKNLN5PEoALCE"
      },
      "source": [
        "from pinecone import Pinecone,ServerlessSpec\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=\"\",  # Replace with your Pinecone API key\n",
        ")\n",
        "\n",
        "# # Create or connect to an index\n",
        "\n",
        "# if index_name not in pinecone.list_indexes():\n",
        "#     pinecone.create_index(index_name, dimension=1536)  # Use 1536 for OpenAI embeddings\n",
        "# index = pinecone.Index(index_name)\n",
        "\n",
        "index_name = \"magic-forest\"\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=1536, # Replace with your model dimensions\n",
        "    spec=ServerlessSpec(\n",
        "        cloud=\"aws\",\n",
        "        region=\"us-east-1\"\n",
        "    )\n",
        ")\n",
        "index = pc.Index(index_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.auth\n",
        "from google.cloud import storage\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Attempt to get the default credentials and project ID\n",
        "credentials, project_id = google.auth.default()\n",
        "print(\"Project ID:\", project_id)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhr4irmpSRKX",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1738527800404,
          "user_tz": 300,
          "elapsed": 1001,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "98e53407-720f-4d10-cf49-564dea6baff7"
      },
      "id": "fhr4irmpSRKX",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project ID: versatile-gist-445618-d0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = storage.Client(credentials=credentials, project=project_id)\n"
      ],
      "metadata": {
        "id": "jfS20OwbVRof",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1738527821604,
          "user_tz": 300,
          "elapsed": 133,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "jfS20OwbVRof",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your bucket name and file path\n",
        "bucket_name = 'magic_forest_plain'\n",
        "file_path = '01-pilot.md'\n",
        "\n",
        "# Access the bucket and blob\n",
        "bucket = client.get_bucket(bucket_name)\n",
        "blob = bucket.blob(file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZJUDHtS4SIuw",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1738528820195,
          "user_tz": 300,
          "elapsed": 143,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "ZJUDHtS4SIuw",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from google.cloud import storage\n",
        "import google.auth\n",
        "\n",
        "# -------------------------------\n",
        "# Step 1: Authenticate and Initialize the GCS Client\n",
        "# -------------------------------\n",
        "credentials, project_id = google.auth.default()\n",
        "client = storage.Client(credentials=credentials, project=project_id)\n",
        "\n",
        "# Replace with your actual bucket name.\n",
        "bucket_name = \"magic_forest_plain\"\n",
        "bucket = client.get_bucket(bucket_name)\n",
        "\n",
        "# -------------------------------\n",
        "# Step 2: List the Chapter Files\n",
        "# -------------------------------\n",
        "# If your 13 files are stored under a common prefix, e.g., \"chapters/\", specify that prefix.\n",
        "blobs = bucket.list_blobs()\n",
        "\n",
        "# Filter for Markdown files (ending in .md) and sort them.\n",
        "chapter_files = sorted([blob.name for blob in blobs if blob.name.endswith('.md')])\n",
        "print(\"Found chapter files:\")\n",
        "for f in chapter_files:\n",
        "    print(\"  \", f)\n",
        "\n",
        "# -------------------------------\n",
        "# Step 3: Define a Function to Split Text into Chunks\n",
        "# -------------------------------\n",
        "def split_text(text, max_chunk_length=500):\n",
        "    \"\"\"\n",
        "    Splits text into smaller chunks with each chunk not exceeding max_chunk_length characters.\n",
        "    This implementation uses sentence boundaries.\n",
        "    \"\"\"\n",
        "    # Split text by sentence endings.\n",
        "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    for sentence in sentences:\n",
        "        # If adding this sentence exceeds our max length, save the current chunk and start a new one.\n",
        "        if len(current_chunk) + len(sentence) > max_chunk_length:\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "        else:\n",
        "            current_chunk += \" \" + sentence\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "    return chunks\n",
        "\n",
        "# -------------------------------\n",
        "# Step 4: Process Each Chapter File and Prepare Data for Indexing\n",
        "# -------------------------------\n",
        "data_for_indexing = []  # This list will hold tuples of (vector_id, text_chunk, metadata)\n",
        "\n",
        "for file_index, file_name in enumerate(chapter_files, start=1):\n",
        "    # Download the chapter file.\n",
        "    blob = bucket.blob(file_name)\n",
        "    chapter_text = blob.download_as_string().decode('utf-8')\n",
        "\n",
        "    # Optionally, extract a chapter title.\n",
        "    # For example, assume the first non-empty line is the chapter title.\n",
        "    lines = chapter_text.splitlines()\n",
        "    chapter_title = None\n",
        "    for line in lines:\n",
        "        if line.strip():\n",
        "            chapter_title = line.strip()\n",
        "            break\n",
        "    if not chapter_title:\n",
        "        chapter_title = f\"Chapter {file_index}\"\n",
        "\n",
        "    # Split the chapter text into smaller chunks.\n",
        "    chunks = split_text(chapter_text, max_chunk_length=500)\n",
        "\n",
        "    # For each chunk, prepare a unique ID and metadata.\n",
        "    for chunk_index, chunk in enumerate(chunks):\n",
        "        vector_id = f\"chapter{file_index}_chunk{chunk_index}\"\n",
        "        metadata = {\n",
        "            \"chapter_file\": file_name,\n",
        "            \"chapter_number\": file_index,\n",
        "            \"chapter_title\": chapter_title,\n",
        "            \"chunk_index\": chunk_index,\n",
        "            \"text\": chunk  # include the chunk text as metadata for reference (optional)\n",
        "        }\n",
        "        data_for_indexing.append((vector_id, chunk, metadata))\n",
        "\n",
        "print(f\"Prepared data for indexing. Total chunks: {len(data_for_indexing)}\")\n",
        "\n",
        "# -------------------------------\n",
        "# (Optional) Example: Print the First Prepared Entry\n",
        "# -------------------------------\n",
        "if data_for_indexing:\n",
        "    example_id, example_text, example_metadata = data_for_indexing[0]\n",
        "    print(\"\\nExample prepared entry:\")\n",
        "    print(\"ID:\", example_id)\n",
        "    print(\"Metadata:\", example_metadata)\n",
        "    print(\"Text snippet:\", example_text[:200])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_SsMEdUV0Rl",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1738530126509,
          "user_tz": 300,
          "elapsed": 880,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "53fa4ea9-1d8b-442b-fcac-a2a68e64bab6"
      },
      "id": "m_SsMEdUV0Rl",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found chapter files:\n",
            "   01-pilot.md\n",
            "   02-enchanted-river-quest.md\n",
            "   03-quest-for-the-lost-amulet.md\n",
            "   04-mystery-of-moonlit-lake.md\n",
            "   05-great-garden-rescue.md\n",
            "   06-tale-of-hidden-truth.md\n",
            "   07-adventure-of-the-whispering-woods.md\n",
            "   08-ocean-of-wonders.md\n",
            "   09-adventure-of-the-starry-sky.md\n",
            "   10-autumn-enchantment.md\n",
            "   11-enchanted-waterfall.md\n",
            "   12-truthful-treetop.md\n",
            "   13-winter-wish.md\n",
            "Prepared data for indexing. Total chunks: 95\n",
            "\n",
            "Example prepared entry:\n",
            "ID: chapter1_chunk0\n",
            "Metadata: {'chapter_file': '01-pilot.md', 'chapter_number': 1, 'chapter_title': '**The Magical Forest Adventure**', 'chunk_index': 0, 'text': '**The Magical Forest Adventure**\\n\\nOnce upon a time, in a village nestled by a great forest, lived a curious little girl named Lily and her brave younger brother, Tom. Every night, they would dream of exploring the magical forest just beyond their home.\\n\\nOne sunny day, they decided to embark on an adventure. With a small backpack filled with snacks and a map drawn by their grandfather, they set off into the forest. As they walked, they discovered the forest was full of wonders.'}\n",
            "Text snippet: **The Magical Forest Adventure**\n",
            "\n",
            "Once upon a time, in a village nestled by a great forest, lived a curious little girl named Lily and her brave younger brother, Tom. Every night, they would dream of \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_for_indexing[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoO6YmxpeuTf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1738530296544,
          "user_tz": 300,
          "elapsed": 133,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "50f6dd8f-d16e-44a2-9d66-bbf8914431e4"
      },
      "id": "JoO6YmxpeuTf",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('chapter1_chunk0', '**The Magical Forest Adventure**\\n\\nOnce upon a time, in a village nestled by a great forest, lived a curious little girl named Lily and her brave younger brother, Tom. Every night, they would dream of exploring the magical forest just beyond their home.\\n\\nOne sunny day, they decided to embark on an adventure. With a small backpack filled with snacks and a map drawn by their grandfather, they set off into the forest. As they walked, they discovered the forest was full of wonders.', {'chapter_file': '01-pilot.md', 'chapter_number': 1, 'chapter_title': '**The Magical Forest Adventure**', 'chunk_index': 0, 'text': '**The Magical Forest Adventure**\\n\\nOnce upon a time, in a village nestled by a great forest, lived a curious little girl named Lily and her brave younger brother, Tom. Every night, they would dream of exploring the magical forest just beyond their home.\\n\\nOne sunny day, they decided to embark on an adventure. With a small backpack filled with snacks and a map drawn by their grandfather, they set off into the forest. As they walked, they discovered the forest was full of wonders.'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"\"\n",
        "\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "    response = openai.embeddings.create(input=[text], model=model)\n",
        "    return response.data[0].embedding\n",
        "\n",
        "# Generate embeddings for all chunks\n",
        "vectors = []  # List to hold tuples (vector_id, embedding, metadata)\n",
        "for vector_id, chunk, metadata in data_for_indexing:\n",
        "    try:\n",
        "        embedding = get_embedding(chunk)\n",
        "        vectors.append((vector_id, embedding, metadata))\n",
        "        print(f\"Generated embedding for {vector_id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embedding for {vector_id}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VtHXPwMebpC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1738530630165,
          "user_tz": 300,
          "elapsed": 51017,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "ae14d4a1-7720-4a81-8f30-3c9506f4560e"
      },
      "id": "9VtHXPwMebpC",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated embedding for chapter1_chunk0\n",
            "Generated embedding for chapter1_chunk1\n",
            "Generated embedding for chapter1_chunk2\n",
            "Generated embedding for chapter1_chunk3\n",
            "Generated embedding for chapter1_chunk4\n",
            "Generated embedding for chapter2_chunk0\n",
            "Generated embedding for chapter2_chunk1\n",
            "Generated embedding for chapter2_chunk2\n",
            "Generated embedding for chapter2_chunk3\n",
            "Generated embedding for chapter2_chunk4\n",
            "Generated embedding for chapter2_chunk5\n",
            "Generated embedding for chapter3_chunk0\n",
            "Generated embedding for chapter3_chunk1\n",
            "Generated embedding for chapter3_chunk2\n",
            "Generated embedding for chapter3_chunk3\n",
            "Generated embedding for chapter3_chunk4\n",
            "Generated embedding for chapter4_chunk0\n",
            "Generated embedding for chapter4_chunk1\n",
            "Generated embedding for chapter4_chunk2\n",
            "Generated embedding for chapter4_chunk3\n",
            "Generated embedding for chapter4_chunk4\n",
            "Generated embedding for chapter4_chunk5\n",
            "Generated embedding for chapter4_chunk6\n",
            "Generated embedding for chapter5_chunk0\n",
            "Generated embedding for chapter5_chunk1\n",
            "Generated embedding for chapter5_chunk2\n",
            "Generated embedding for chapter5_chunk3\n",
            "Generated embedding for chapter5_chunk4\n",
            "Generated embedding for chapter5_chunk5\n",
            "Generated embedding for chapter5_chunk6\n",
            "Generated embedding for chapter5_chunk7\n",
            "Generated embedding for chapter5_chunk8\n",
            "Generated embedding for chapter6_chunk0\n",
            "Generated embedding for chapter6_chunk1\n",
            "Generated embedding for chapter6_chunk2\n",
            "Generated embedding for chapter6_chunk3\n",
            "Generated embedding for chapter6_chunk4\n",
            "Generated embedding for chapter6_chunk5\n",
            "Generated embedding for chapter6_chunk6\n",
            "Generated embedding for chapter7_chunk0\n",
            "Generated embedding for chapter7_chunk1\n",
            "Generated embedding for chapter7_chunk2\n",
            "Generated embedding for chapter7_chunk3\n",
            "Generated embedding for chapter7_chunk4\n",
            "Generated embedding for chapter7_chunk5\n",
            "Generated embedding for chapter7_chunk6\n",
            "Generated embedding for chapter8_chunk0\n",
            "Generated embedding for chapter8_chunk1\n",
            "Generated embedding for chapter8_chunk2\n",
            "Generated embedding for chapter8_chunk3\n",
            "Generated embedding for chapter8_chunk4\n",
            "Generated embedding for chapter8_chunk5\n",
            "Generated embedding for chapter8_chunk6\n",
            "Generated embedding for chapter8_chunk7\n",
            "Generated embedding for chapter9_chunk0\n",
            "Generated embedding for chapter9_chunk1\n",
            "Generated embedding for chapter9_chunk2\n",
            "Generated embedding for chapter9_chunk3\n",
            "Generated embedding for chapter9_chunk4\n",
            "Generated embedding for chapter9_chunk5\n",
            "Generated embedding for chapter9_chunk6\n",
            "Generated embedding for chapter9_chunk7\n",
            "Generated embedding for chapter9_chunk8\n",
            "Generated embedding for chapter10_chunk0\n",
            "Generated embedding for chapter10_chunk1\n",
            "Generated embedding for chapter10_chunk2\n",
            "Generated embedding for chapter10_chunk3\n",
            "Generated embedding for chapter10_chunk4\n",
            "Generated embedding for chapter10_chunk5\n",
            "Generated embedding for chapter10_chunk6\n",
            "Generated embedding for chapter10_chunk7\n",
            "Generated embedding for chapter10_chunk8\n",
            "Generated embedding for chapter11_chunk0\n",
            "Generated embedding for chapter11_chunk1\n",
            "Generated embedding for chapter11_chunk2\n",
            "Generated embedding for chapter11_chunk3\n",
            "Generated embedding for chapter11_chunk4\n",
            "Generated embedding for chapter11_chunk5\n",
            "Generated embedding for chapter11_chunk6\n",
            "Generated embedding for chapter11_chunk7\n",
            "Generated embedding for chapter12_chunk0\n",
            "Generated embedding for chapter12_chunk1\n",
            "Generated embedding for chapter12_chunk2\n",
            "Generated embedding for chapter12_chunk3\n",
            "Generated embedding for chapter12_chunk4\n",
            "Generated embedding for chapter12_chunk5\n",
            "Generated embedding for chapter12_chunk6\n",
            "Generated embedding for chapter13_chunk0\n",
            "Generated embedding for chapter13_chunk1\n",
            "Generated embedding for chapter13_chunk2\n",
            "Generated embedding for chapter13_chunk3\n",
            "Generated embedding for chapter13_chunk4\n",
            "Generated embedding for chapter13_chunk5\n",
            "Generated embedding for chapter13_chunk6\n",
            "Generated embedding for chapter13_chunk7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone,ServerlessSpec\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=\"\",  # Replace with your Pinecone API key\n",
        ")\n",
        "\n",
        "# # Create or connect to an index\n",
        "\n",
        "# if index_name not in pinecone.list_indexes():\n",
        "#     pinecone.create_index(index_name, dimension=1536)  # Use 1536 for OpenAI embeddings\n",
        "# index = pinecone.Index(index_name)\n",
        "\n",
        "index_name = \"magic-forest\"\n",
        "\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Determine embedding dimension (for text-embedding-ada-002, it's typically 1536)\n",
        "embedding_dimension = len(vectors[0][1]) if vectors else 1536\n",
        "\n",
        "\n",
        "# Upsert the vectors in batches (if many vectors, batching helps)\n",
        "batch_size = 100\n",
        "for i in range(0, len(vectors), batch_size):\n",
        "    batch = vectors[i:i+batch_size]\n",
        "    # Pinecone upsert expects a list of tuples: (id, vector, metadata)\n",
        "    index.upsert(vectors=batch)\n",
        "    print(f\"Upserted batch {i // batch_size + 1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHoL_TzlgRTr",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1738530825309,
          "user_tz": 300,
          "elapsed": 1204,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "ba1b5a1d-926b-42d0-db1f-b338adfb74ae"
      },
      "id": "cHoL_TzlgRTr",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upserted batch 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search_book(query, top_k=3):\n",
        "    \"\"\"\n",
        "    Search the indexed book for the most relevant chunks based on a query.\n",
        "\n",
        "    :param query: User's search string\n",
        "    :param top_k: Number of results to return\n",
        "    :return: List of matching text chunks with metadata\n",
        "    \"\"\"\n",
        "    # Convert the query to an embedding\n",
        "    query_embedding = get_embedding(query)\n",
        "\n",
        "    # Search in Pinecone\n",
        "    query_response = index.query(vector=query_embedding, top_k=top_k, include_metadata=True)\n",
        "\n",
        "    # Extract results\n",
        "    results = []\n",
        "    for match in query_response[\"matches\"]:\n",
        "        metadata = match[\"metadata\"]\n",
        "        results.append({\n",
        "            \"id\": match[\"id\"],\n",
        "            \"score\": match[\"score\"],\n",
        "            \"chapter_number\": metadata[\"chapter_number\"],\n",
        "            \"chapter_title\": metadata[\"chapter_title\"],\n",
        "            \"text_snippet\": metadata[\"text\"][:300],  # Show first 300 characters\n",
        "        })\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "MUD3WcKWihA2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1738531318000,
          "user_tz": 300,
          "elapsed": 116,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "MUD3WcKWihA2",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"who is Felix\"\n",
        "results = search_book(query, top_k=5)\n",
        "\n",
        "print(\"\\nüîç **Search Results:**\\n\")\n",
        "for result in results:\n",
        "    print(f\"üìñ **Chapter {result['chapter_number']}: {result['chapter_title']}**\")\n",
        "    print(f\"üîπ **Relevance Score:** {result['score']:.4f}\")\n",
        "    print(f\"üìù **Snippet:** {result['text_snippet']}...\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzNPnJrzhDF0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1738531395270,
          "user_tz": 300,
          "elapsed": 277,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e0083a91-8a5f-4083-8604-9152a40dd29f"
      },
      "id": "MzNPnJrzhDF0",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç **Search Results:**\n",
            "\n",
            "üìñ **Chapter 11.0: **Lily, Tom, and the Enchanted Waterfall****\n",
            "üîπ **Relevance Score:** 0.7191\n",
            "üìù **Snippet:** \"What‚Äôs going on, Felix?\"\n",
            "\n",
            "Felix took a deep breath. \"The waterfall‚Ä¶ it‚Äôs stopped flowing! The animals are worried because it brings life to the forest. Without its water, the flowers are wilting, and the animals are losing their sparkle.\"\n",
            "\n",
            "Tom held up his never-lost compass, which immediately point...\n",
            "\n",
            "üìñ **Chapter 13.0: **The Winter Wish****\n",
            "üîπ **Relevance Score:** 0.7158\n",
            "üìù **Snippet:** He‚Äôs known for stealing shiny things to hoard in his frozen lair.‚Äù\n",
            "\n",
            "‚ÄúWe have to get it back!‚Äù Lily said firmly.\n",
            "\n",
            "Felix led them through the snow-covered forest, their boots crunching softly in the frosty stillness. The trees sparkled with icicles, and the air smelled of pine and snow. As they walked...\n",
            "\n",
            "üìñ **Chapter 11.0: **Lily, Tom, and the Enchanted Waterfall****\n",
            "üîπ **Relevance Score:** 0.7151\n",
            "üìù **Snippet:** **Lily, Tom, and the Enchanted Waterfall**\n",
            "\n",
            "One bright, sunny morning, Lily and Tom were sitting by the edge of the magic forest, listening to the soft rustling of leaves. Suddenly, they saw a familiar flash of orange‚Äîa fox with a bushy tail and twinkling eyes. It was Felix, rushing toward them!\n",
            "\n",
            "\"L...\n",
            "\n",
            "üìñ **Chapter 1.0: **The Magical Forest Adventure****\n",
            "üîπ **Relevance Score:** 0.7125\n",
            "üìù **Snippet:** They saw flowers that changed colors, trees that whispered secrets, and animals that talked!\n",
            "\n",
            "Suddenly, a friendly fox named Felix appeared. \"Welcome to the Magical Forest,\" he said with a bow. \"Would you like to meet the Queen of the Forest?\"\n",
            "\n",
            "Excitedly, Lily and Tom nodded. Felix led them through ...\n",
            "\n",
            "üìñ **Chapter 12.0: **Lily, Tom, and the Truthful Treetop****\n",
            "üîπ **Relevance Score:** 0.7106\n",
            "üìù **Snippet:** **Lily, Tom, and the Truthful Treetop**\n",
            "\n",
            "It was a crisp autumn morning in the magic forest. Lily and Tom were collecting colorful leaves to press into their scrapbook. Felix, the clever fox, trotted up to them, his fur shining like a warm fire in the sunlight.\n",
            "\n",
            "‚ÄúHello, Felix!‚Äù Lily said. ‚ÄúWhat bring...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_from_retrieval(query, top_k=3, model=\"gpt-4\", max_tokens=200):\n",
        "    \"\"\"\n",
        "    Generates text based on retrieved relevant chunks from Pinecone.\n",
        "\n",
        "    :param query: User's input query\n",
        "    :param top_k: Number of retrieved chunks to use as context\n",
        "    :param model: OpenAI model to use (e.g., \"gpt-4\", \"gpt-3.5-turbo\")\n",
        "    :param max_tokens: Max tokens for output generation\n",
        "    :return: Generated response from GPT\n",
        "    \"\"\"\n",
        "    # Step 1: Retrieve the most relevant text chunks from Pinecone\n",
        "    retrieved_results = search_book(query, top_k=top_k)\n",
        "\n",
        "    # Step 2: Format retrieved text as context\n",
        "    retrieved_texts = \"\\n\\n\".join(\n",
        "        [f\"Chapter {r['chapter_number']}: {r['chapter_title']}\\n{r['text_snippet']}\" for r in retrieved_results]\n",
        "    )\n",
        "\n",
        "    # Step 3: Construct a detailed prompt for GPT\n",
        "    prompt = f\"\"\"\n",
        "    You are a helpful AI assistant specialized in summarizing children's stories.\n",
        "    Below are some relevant excerpts from a children's book related to the user's query:\n",
        "\n",
        "    {retrieved_texts}\n",
        "\n",
        "    Based on the above content, answer the following question in a clear and engaging manner:\n",
        "\n",
        "    **Question:** {query}\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 4: Use OpenAI's API to generate a response\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful storytelling assistant.\"},\n",
        "                  {\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "R6mCy2nsi_5Q",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1738531501038,
          "user_tz": 300,
          "elapsed": 112,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "R6mCy2nsi_5Q",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Does lily also have a tool?\"\n",
        "generated_text = generate_text_from_retrieval(query, top_k=3)\n",
        "\n",
        "print(\"\\n‚ú® **Generated Story Response:**\\n\")\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl21wXLWjX-D",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1738531708548,
          "user_tz": 300,
          "elapsed": 4216,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d67baefb-d8fb-4099-d0e3-f431a11645fb"
      },
      "id": "Fl21wXLWjX-D",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ú® **Generated Story Response:**\n",
            "\n",
            "Yes, Lily does have a tool. In the 'Magical Forest Adventure' chapter, Lily was granted a wish by the Queen. She chose the power to talk to animals, which, while not a physical tool like Tom's magical compass, is a special ability that functions as a tool for them in their various adventures.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V5yYniVAgPP3"
      },
      "id": "V5yYniVAgPP3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "dlin24799 (Feb 2, 2025, 3:00:44‚ÄØPM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}